{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   diagnosis  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('Breast_cancer_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean_radius        float64\n",
       "mean_texture       float64\n",
       "mean_perimeter     float64\n",
       "mean_area          float64\n",
       "mean_smoothness    float64\n",
       "diagnosis          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.use_inf_as_na = True\n",
    "data.fillna(1)\n",
    "data.columns[data.isnull().any()]\n",
    "print(data.isnull().values.any())\n",
    "data = data.astype(\"float\")\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.867\n",
      "Accuracy:  0.867\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))\n",
    "\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='gini',splitter = 'random')\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.846\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.888\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.867\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 10)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.881\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.888\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 15)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.874\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5, max_features \\\n",
    "                           = 5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.881\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5, max_features \\\n",
    "                           = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.615\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5, max_features \\\n",
    "                           = 5, min_impurity_decrease = 10)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://medium.com/analytics-steps/understanding-the-gini-index-and-information-gain-in-decision-trees-ab4720518ba8\\n\\nUsing the intial DecisionTreeClassifier with all the default values but with the \"entropy\" function in order to measure\\nthe quality of when the tree splits, the classifier manages to get an accuracy score of 0.86. Already showing a good score \\nregarding predictions. Following that I still used the \\'entropy\\' criterion but also changed the splitter parameter to see\\nhow well the model does with a \"random\" strategy for splitting the data. Surprisingly, the model is able to get a better\\nscore. This may have to do with how for a \"random\" split it has the ability of going through all the features of a \\ndataset and then choosing the better ones for splitting from that while for \"best\" it only goes with the feature that \\nit deems to be the most useful for determining the results. Regardless though both of the scores are pretty similar and \\neach splitter method would still loop through all of the \"relevant\" data.\\n\\n\\nI next wanted to see how well the model does when using the other criterion \"gini\". Even when using both the splitter \\nmethods, both outcomes have a better accuracy score than the \"entropy\" function. This may be due to how a \"gini\" index\\noperates mainly on categorical variables and whether they are a success or failure. This basically makes it the perfect\\nfunction to use with this data as it is trying to classify whether a patient would have cancer or not.\\n\\nWith that in mind I decided to continue testing the Decision tree with the \"entropy\" function to see if it could get better\\nresults. The next test involved changing with the max_depth parameter. Based on the results a higher max_depth seems to\\ndo better than a lower depth which resulted in the lowest score seen so far in the testing. This proves the statement made\\nin the class notes on how the lower the depth the less acurate the results would be. On the other hand the higher the depth\\nthe more likely the model has of overfitting, but given how the score was not higher than any of the \"gini\" scores I do not\\nthink that is an issue yet. From there I test the min_sample_fit parameter. From this it appears that the higher this \\nparameter goes the higher the accuracy which is taking the score into the 90 percentile. While this is good I still need\\nto watch out for overfitting so I just continue on with a low number for that. With he max_features parameter the highest\\nnumber that can be used for this dataset would be 5. Luckily the usual trade off of taking a longer time processing does\\nnot seem to affect this dataset. The last parameter I try to test is the \"min_impurity_decrease\". This parameter does not \\nseem to have any kind of affect on the model as regardless of what value I use it always ends up having a score of 0.615.\\n\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "https://medium.com/analytics-steps/understanding-the-gini-index-and-information-gain-in-decision-trees-ab4720518ba8\n",
    "\n",
    "Using the intial DecisionTreeClassifier with all the default values but with the \"entropy\" function in order to measure\n",
    "the quality of when the tree splits, the classifier manages to get an accuracy score of 0.86. Already showing a good score \n",
    "regarding predictions. Following that I still used the 'entropy' criterion but also changed the splitter parameter to see\n",
    "how well the model does with a \"random\" strategy for splitting the data. Surprisingly, the model is able to get a better\n",
    "score. This may have to do with how for a \"random\" split it has the ability of going through all the features of a \n",
    "dataset and then choosing the better ones for splitting from that while for \"best\" it only goes with the feature that \n",
    "it deems to be the most useful for determining the results. Regardless though both of the scores are pretty similar and \n",
    "each splitter method would still loop through all of the \"relevant\" data.\n",
    "\n",
    "\n",
    "I next wanted to see how well the model does when using the other criterion \"gini\". Even when using both the splitter \n",
    "methods, both outcomes have a better accuracy score than the \"entropy\" function. This may be due to how a \"gini\" index\n",
    "operates mainly on categorical variables and whether they are a success or failure. This basically makes it the perfect\n",
    "function to use with this data as it is trying to classify whether a patient would have cancer or not.\n",
    "\n",
    "With that in mind I decided to continue testing the Decision tree with the \"entropy\" function to see if it could get better\n",
    "results. The next test involved changing with the max_depth parameter. Based on the results a higher max_depth seems to\n",
    "do better than a lower depth which resulted in the lowest score seen so far in the testing. This proves the statement made\n",
    "in the class notes on how the lower the depth the less acurate the results would be. On the other hand the higher the depth\n",
    "the more likely the model has of overfitting, but given how the score was not higher than any of the \"gini\" scores I do not\n",
    "think that is an issue yet. From there I test the min_sample_fit parameter. From this it appears that the higher this \n",
    "parameter goes the higher the accuracy which is taking the score into the 90 percentile. While this is good I still need\n",
    "to watch out for overfitting so I just continue on with a low number for that. With he max_features parameter the highest\n",
    "number that can be used for this dataset would be 5. Luckily the usual trade off of taking a longer time processing does\n",
    "not seem to affect this dataset. The last parameter I try to test is the \"min_impurity_decrease\". This parameter does not \n",
    "seem to have any kind of affect on the model as regardless of what value I use it always ends up having a score of 0.615.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_model = BaggingClassifier(base_estimator=SVC(),n_estimators=3, random_state=0)\n",
    "bag_model.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boost_model = GradientBoostingClassifier(n_estimators = 3, random_state = 0)\n",
    "boost_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.892 (0.089)\n",
      "Boost Accuracy: 0.874 (0.098)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "bag_scores = cross_val_score(bag_model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Bagging Accuracy: %.3f (%.3f)' % (mean(bag_scores), std(bag_scores)))\n",
    "\n",
    "boost_scores = cross_val_score(boost_model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Boost Accuracy: %.3f (%.3f)' % (mean(boost_scores), std(boost_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor this problem I tried to make both models as similar as possible hence whey they each of the same number of \\nn_repeats and random_state values, in order to try and make their results more noticeable should they be different.\\nThe results show that the Bagging model had a greater accuracy in when making predictions, but the scores were still\\nvery close together. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For this problem I tried to make both models as similar as possible hence whey they each of the same number of \n",
    "n_repeats and random_state values, in order to try and make their results more noticeable should they be different.\n",
    "The results show that the Bagging model had a greater accuracy in when making predictions, but the scores were still\n",
    "very close together. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37258347978910367\n",
      "0.6274165202108963\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_algorithms_performance_metrics.htm\n",
    "# https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n",
    "print(len(y[y == 0])/len(y))\n",
    "print(len(y[y == 1])/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree Accuracy:  0.846\n",
      "Bag Classifier Accuracy:  0.888\n",
      "Boost Classifier Accuracy:  0.853\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5, max_features \\\n",
    "                           = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "# Make  the Confusion Matrix and calculate  model accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Decision tree Accuracy: \",round(np.trace(cm)/np.sum(cm),3))\n",
    "\n",
    "y_bag_pred = bag_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_bag_pred)\n",
    "print(\"Bag Classifier Accuracy: \",round(np.trace(cm)/np.sum(cm),3))\n",
    "\n",
    "y_boost_pred = boost_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_boost_pred)\n",
    "print(\"Boost Classifier Accuracy: \",round(np.trace(cm)/np.sum(cm),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSeeing as how each model is using a dataset to try and predict a 0 or 1 classification value I figured using the\\nConfusion Matrix would be the ideal metric to use, or more specifically the accuracy metric of the confusion matrix.\\nFrom readings and my own research, using an accuracy metric is ideal when the target variables are nearly balanced. And \\nfor this dataset the 2 target variables, 0 and 1, respectively make up 37% and 63% of the target data putting them in a\\ngood range for using accuracy.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Seeing as how each model is using a dataset to try and predict a 0 or 1 classification value I figured using the\n",
    "Confusion Matrix would be the ideal metric to use, or more specifically the accuracy metric of the confusion matrix.\n",
    "From readings and my own research, using an accuracy metric is ideal when the target variables are nearly balanced. And \n",
    "for this dataset the 2 target variables, 0 and 1, respectively make up 37% and 63% of the target data putting them in a\n",
    "good range for using accuracy.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGLOSS Value for Decision tree is 4.589135291415842\n",
      "LOGLOSS Value for Bag classifier is 3.8645455768372967\n",
      "LOGLOSS Value for Boost classifier is 5.072239833858241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy',splitter = 'random', max_depth = 10, min_samples_split = 5, max_features \\\n",
    "                           = 3)\n",
    "dt.fit(X_train, y_train)\n",
    "# Predict the Test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('LOGLOSS Value for Decision tree is',log_loss(y_test, y_pred))\n",
    "\n",
    "y_bag_pred = bag_model.predict(X_test)\n",
    "print('LOGLOSS Value for Bag classifier is',log_loss(y_test, y_bag_pred))\n",
    "\n",
    "y_boost_pred = boost_model.predict(X_test)\n",
    "print('LOGLOSS Value for Boost classifier is',log_loss(y_test, y_boost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing a different metric could also be useful, but depending on the metric I would also have to try and change the data \\naround in order to make a working classifier. For example the LOGLOSS metric. The output it is giving me is not the normal \\npercentage decimal numbers that one would usually receive to indicate an accuracy percentage. This might be because with \\nlogloss it is a cross-entropy loss function that tries to classify probability values that are between 0 and 1 which can \\nalso be affected by the number of features being used. Showing that not every function will work with a dataset as one \\nwould like and that finding the correct ones to properly show the results takes a lot of trial and error to see what works.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using a different metric could also be useful, but depending on the metric I would also have to try and change the data \n",
    "around in order to make a working classifier. For example the LOGLOSS metric. The output it is giving me is not the normal \n",
    "percentage decimal numbers that one would usually receive to indicate an accuracy percentage. This might be because with \n",
    "logloss it is a cross-entropy loss function that tries to classify probability values that are between 0 and 1 which can \n",
    "also be affected by the number of features being used. Showing that not every function will work with a dataset as one \n",
    "would like and that finding the correct ones to properly show the results takes a lot of trial and error to see what works.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
